<!doctype html>
<html>
<head>
	<title>klab</title>
	<meta charset="utf-8">
    <meta name="viewport" content="width=device-width initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <meta name="author" content="Jonas Kubilius">
    <meta name="description" content="">
    <meta name="keywords" content="mid-level vision, computer vision, human vision">
    <meta name="google-site-verification" content="k1wISsyM_ADFRsWYOmwrowOMYSYu3MV5afsd-8B2AuQ" />
    <meta content="Convolutional recurrent neural network models of dynamics in higher visual cortex" property="og:title" />

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/3.0.3/normalize.min.css" type="text/css"/>
	<link rel="stylesheet" href="https://klab.lt/css/style.css" type="text/css" media="screen" />
	<link rel="shortcut icon" href="https://klab.lt/favicon.ico" />
</head>

<body>
    <div class="page-wrap">
        <header>
            <div class="logo-container">
                <a href="https://klab.lt">
                    <div class="logo"></div>
                    <div class="logo-name">klab</div>
                </a>
                <div class="clear"></div>
                <div class="tagline">&#34;What I cannot create, I do not understand.&#34; – R. Feynman</div>
            </div>

            <nav>
                <ul>                    <li>                        <a href="https://klab.lt/blog/">Blog</a>
                                            </li>                    <li>                        Publications
                        <ul>                            <li><a href="https://klab.lt/publications/papers/">Papers</a></li>                            <li><a href="https://klab.lt/publications/posters/">Posters</a></li>                            <li><a href="https://klab.lt/publications/talks/">Talks</a></li>                            <li><a href="https://klab.lt/publications/figures/">Figures</a></li>                        </ul>
                                            </li>                    <li>                        Education
                        <ul>                            <li><a href="https://klab.lt/education/lectures/">Lectures</a></li>                        </ul>
                                            </li>                    <li>                        About
                        <ul>                            <li><a href="https://klab.lt/about/me/">Me</a></li>                            <li><a href="https://dl.dropboxusercontent.com/u/2498793/Kubilius-CV.pdf">My CV</a></li>                            <li><a href="https://klab.lt/about/media/">Media</a></li>                        </ul>
                                            </li>                </ul>
            </nav>
        </header>

        <div class="main-container">
<div class="content">
    <span class="pub-authors">
        Aran Nayebi*, Jonas Kubilius*, Daniel Bear, Surya Ganguli, James J. DiCarlo, Daniel L. K. Yamins
    </span>

    <h1>Convolutional recurrent neural network models of dynamics in higher visual cortex</h1>

    <span class="pub-journal">
         Cosyne
    </span>


    <span class="datea">, 2018-03-01</span>




        <span class="pub-links">
                    <a href="nayebi-kubilius_cosyne2018_poster.pdf">poster</a>
              <!--  -->
                    <a href="nayebi-kubilius_cosyne2018_suppl.pdf">supplementary</a>
              <!--  -->
    </span>
    <div class="article-content">
         <p>Neurons in the ventral visual pathway exhibit behaviorally relevant temporal dynamics during image viewing. However, the most accurate existing computational models of this system are feedforward hierarchical convolutional neural networks (HCNNs), which capture neurons’ time-averaged responses, but do not account well for their complex temporal trajectories. Here we show that HCNNs augmented with both local and global recurrent connections are quantitatively accurate models of dynamics in higher visual cortex.</p>
<p>We began with a five-layer HCNN that achieved state-of-the-art predictions of temporally-averaged visual responses in macaque V4 and IT neurons. To model within-area dynamics, we replaced units in each layer with one of several local recurrent circuit motifs, including simple Recurrent Neural Networks (RNNs), Gated Recurrent Units (GRUs), and Long Short-Term Memory (LSTM) units. We also included combinations of global feedback connections, in which outputs of later convolutional layers were added to inputs of earlier layers. Using backpropagation through time, these new parameters were optimized to predict V4 and IT neural response patterns. Finally, we tested these networks’ ability to predict responses on held-out images and neurons not used for model optimization.</p>
<p>We found that the best network structure led to substantial improvements over the feedforward baseline, explaining close to 100% of the explainable variance in V4 neurons and above 75% in IT neurons on average across time points. This network made use of gated local recurrence, with LSTMs and GRUs proving superior to simple RNNs. Furthermore, the presence of specific global feedback connections in this network was critical for best predicting V4 neuron dynamics. In summary, we have developed a deep recurrent neural network architecture that accurately captures temporal dynamics in several ventral cortical areas, opening the door to more detailed computational study of the circuit structures underlying complex visual behaviors.</p>     </div>

    <div class="clear"></div>
</div>

<div class="clear"></div>
</div>

                <footer>
            (<a href="https://creativecommons.org/licenses/by/4.0/">cc-by</a>) 2012-2018 klab.lt &bull; source code available on <a href="https://github.com/qbilius/klab/" target="_blank">GitHub</a>
        </footer>
            </div>

</body>
</html>